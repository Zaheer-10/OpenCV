{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d1e5b45",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1>Object Detection and Object Tracking Using HSV Color Space </h1>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bc0285",
   "metadata": {},
   "source": [
    "### What is HSV Color Space?\n",
    " - HSV stands for `Hue`, `Saturation`, `and Value`. \n",
    "    \n",
    "- It is a cylindrical color space that represents colors in terms of their hue, saturation, and value. \n",
    "\n",
    "- Hue is the color component, which ranges from `0 to 360 degrees`.\n",
    "            \n",
    " - Saturation is the amount of color present in the color, which ranges from `0% (desaturated) to 100% (saturated)`. \n",
    "\n",
    "- Value is the brightness of the color, which ranges from 0% (black) to 100% (white)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdb80a8",
   "metadata": {},
   "source": [
    "#### HSV color space is useful for color-based object detection because it separates the color information from the brightness information, making it robust to changes in lighting conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cabc7b4",
   "metadata": {},
   "source": [
    "## How to Convert an Image from BGR to HSV Color Space?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec1ba54",
   "metadata": {},
   "source": [
    "OpenCV uses BGR (Blue, Green, Red) as its default color space for images. To convert an image from BGR to HSV, we can use the cv2.cvtColor() function and pass the cv2.COLOR_BGR2HSV flag as an argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36b64f7f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImages\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmessi1.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Convert from BGR to HSV\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m hsv \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2HSV\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read an image\n",
    "image = cv2.imread('Images\\messi1.jpg')\n",
    "\n",
    "# Convert from BGR to HSV\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da824409",
   "metadata": {},
   "source": [
    "## How to Define a Color Range in HSV?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123a5319",
   "metadata": {},
   "source": [
    "To define a color range in HSV, we need to specify the lower and upper bounds of the hue, saturation, and value components. For example, if we want to detect the color red, we can use the following range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47defa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lower and upper bounds of red\n",
    "lower_red = np.array([0, 50, 50])\n",
    "upper_red = np.array([10, 255, 255])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902726d0",
   "metadata": {},
   "source": [
    "Note that the hue component wraps around at 180 degrees in OpenCV, so we need to use two ranges for red: one from 0 to 10 degrees and another from 170 to 180 degrees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496a18d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How to Perform Color-Based Object Detection in Images?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4259040",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### To perform color-based object detection in images, we need to follow these steps:\n",
    "\n",
    "1. Read an image and convert it from BGR to HSV color space.\n",
    "2. Define a color range in HSV.\n",
    "3. Create a mask by thresholding the HSV image using the color range.\n",
    "4. Apply some morphological operations (such as opening and closing) to remove noise and fill gaps in the mask.\n",
    "5. Find contours in the mask and draw bounding boxes around them on the original image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b0bec9",
   "metadata": {},
   "source": [
    "### Here is an example of how to detect red objects in an image:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efcdd6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read an image\n",
    "img = cv2.imread(\"Images\\colorballs.jpg\")\n",
    "\n",
    "# Convert from BGR to HSV\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Define lower and upper bounds of red\n",
    "lower_red1 = np.array([0, 50, 50])\n",
    "upper_red1 = np.array([10, 255, 255])\n",
    "lower_red2 = np.array([170, 50, 50])\n",
    "upper_red2 = np.array([180, 255, 255])\n",
    "\n",
    "# Create masks for red\n",
    "mask1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
    "mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "mask = mask1 + mask2\n",
    "\n",
    "# Apply morphological operations\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# Find contours in the mask\n",
    "contours, hierarchy = cv2.findContours(mask,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Draw bounding boxes around contours\n",
    "for cnt in contours:\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),3)\n",
    "\n",
    "# Show the result\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d60e1a2",
   "metadata": {},
   "source": [
    "## How to Perform Color-Based Object Tracking in Videos? (Blue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae19e90",
   "metadata": {},
   "source": [
    "To perform color-based object tracking in videos, we need to follow the same steps as above, but instead of reading an image, we need to read a video frame by frame using the cv2.VideoCapture() function. We also need to use a while loop to process each frame until the video ends or the user presses a key. Here is an example of how to track a blue object in a video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb587680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Capture a video\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Define lower and upper bounds of blue\n",
    "lower_blue = np.array([110, 50, 50])\n",
    "upper_blue = np.array([130, 255, 255])\n",
    "\n",
    "# Create a kernel for morphological operations\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "\n",
    "# Loop until the video ends or the user presses a key\n",
    "while True:\n",
    "    # Read a frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if the frame is valid\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert from BGR to HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Create a mask for blue\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "    # Apply morphological operations\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Find contours in the mask\n",
    "    contours, hierarchy = cv2.findContours(mask,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Draw bounding boxes around contours\n",
    "    for cnt in contours:\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),3)\n",
    "\n",
    "    # Show the result\n",
    "    cv2.imshow(\"Video\", frame)\n",
    "\n",
    "    # Wait for a key press or 25 ms\n",
    "    key = cv2.waitKey(25) & 0xFF\n",
    "\n",
    "    # Break the loop if the user presses 'q'\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddacf261",
   "metadata": {},
   "source": [
    "## How to Perform Color-Based Object Tracking in Videos?(With Track Bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b964ef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "cap = cv2.VideoCapture(0);\n",
    "\n",
    "cv2.namedWindow(\"Tracking\")\n",
    "cv2.createTrackbar(\"LH\", \"Tracking\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"LS\", \"Tracking\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"LV\", \"Tracking\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"UH\", \"Tracking\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"US\", \"Tracking\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"UV\", \"Tracking\", 255, 255, nothing)\n",
    "\n",
    "while True:\n",
    "    #frame = cv2.imread('smarties.png')\n",
    "    _, frame = cap.read()\n",
    "\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    l_h = cv2.getTrackbarPos(\"LH\", \"Tracking\")\n",
    "    l_s = cv2.getTrackbarPos(\"LS\", \"Tracking\")\n",
    "    l_v = cv2.getTrackbarPos(\"LV\", \"Tracking\")\n",
    "\n",
    "    u_h = cv2.getTrackbarPos(\"UH\", \"Tracking\")\n",
    "    u_s = cv2.getTrackbarPos(\"US\", \"Tracking\")\n",
    "    u_v = cv2.getTrackbarPos(\"UV\", \"Tracking\")\n",
    "\n",
    "    l_b = np.array([l_h, l_s, l_v])\n",
    "    u_b = np.array([u_h, u_s, u_v])\n",
    "\n",
    "    mask = cv2.inRange(hsv, l_b, u_b)\n",
    "\n",
    "    res = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    cv2.imshow(\"mask\", mask)\n",
    "    cv2.imshow(\"res\", res)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae63c252",
   "metadata": {},
   "source": [
    "## How to Perform Color-Based Object Tracking in Pictures?(With Track Bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b088b439",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:2561: error: (-27:Null pointer) NULL window: 'Tracking' in function 'cvGetTrackbarPos'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 20\u001b[0m\n\u001b[0;32m     16\u001b[0m frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImages\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcolorballs.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m hsv \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2HSV)\n\u001b[1;32m---> 20\u001b[0m l_h \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetTrackbarPos\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLH\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTracking\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m l_s \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mgetTrackbarPos(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLS\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTracking\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m l_v \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mgetTrackbarPos(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLV\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTracking\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:2561: error: (-27:Null pointer) NULL window: 'Tracking' in function 'cvGetTrackbarPos'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow(\"Tracking\")\n",
    "cv2.createTrackbar(\"LH\", \"Tracking\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"LS\", \"Tracking\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"LV\", \"Tracking\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"UH\", \"Tracking\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"US\", \"Tracking\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"UV\", \"Tracking\", 255, 255, nothing)\n",
    "\n",
    "while True:\n",
    "    frame = cv2.imread(\"Images\\colorballs.jpg\")\n",
    "\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    l_h = cv2.getTrackbarPos(\"LH\", \"Tracking\")\n",
    "    l_s = cv2.getTrackbarPos(\"LS\", \"Tracking\")\n",
    "    l_v = cv2.getTrackbarPos(\"LV\", \"Tracking\")\n",
    "\n",
    "    u_h = cv2.getTrackbarPos(\"UH\", \"Tracking\")\n",
    "    u_s = cv2.getTrackbarPos(\"US\", \"Tracking\")\n",
    "    u_v = cv2.getTrackbarPos(\"UV\", \"Tracking\")\n",
    "\n",
    "    l_b = np.array([l_h, l_s, l_v])\n",
    "    u_b = np.array([u_h, u_s, u_v])\n",
    "\n",
    "    mask = cv2.inRange(hsv, l_b, u_b)\n",
    "\n",
    "    res = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    cv2.imshow(\"mask\", mask)\n",
    "    cv2.imshow(\"res\", res)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
